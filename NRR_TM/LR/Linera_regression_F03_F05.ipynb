{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9be1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stat\n",
    "import pylab \n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.linear_model import LogisticRegression as LGR,Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fcfc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fe_CAAC_dataset = df = pd.read_excel(\"F:\\\\Nitrogen_activation\\\\rajaraman\\\\office\\\\ofifice\\\\jupyter\\\\Extension\\\\T07\\\\heatmap\\\\agostic\\\\LR_F03_F05\\\\N2_activation_extension_T07_heatmap_agostaic_descrptors.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4e6a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df.drop(['F00','T01','T02','T03',],axis=1)\n",
    "df_2=df_1.drop([0,18,9])\n",
    "df_3=df_1.drop([0,18,9,8,26,17])\n",
    "df_4=df_1.drop([8,26,17])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab151bb4",
   "metadata": {},
   "source": [
    "# F03_F05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de56ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared Error :  0.8413535674575339\n",
      "mean_absolute_error :  13.118062076435379\n",
      "R squared Error :  0.7462740054252227\n",
      "mean_absolute_error :  9.428308170654585\n",
      "[0.75942544 0.82134143]\n",
      "0.7903834320823329\n",
      "[0.63233837 0.80737957 0.87436083 0.6996905 ]\n",
      "0.7534423196702166\n",
      "149.09587255470728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F03</td>\n",
       "      <td>-89.972001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F05</td>\n",
       "      <td>-16.243717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features      coeff\n",
       "0      F03 -89.972001\n",
       "1      F05 -16.243717"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = df.drop(['F01','F04','F05','F06','F07','F08','F09','F10','F11','F12','F13','F14','F15','T01','T02','T03','T04','T05'],axis=1)\n",
    "#X = df_3.drop(['F01','F02','F19','F08','F03','F14','F07','F15','F17','F18','F09','F16','F11','F05','F04','T01','T07','T03','T04','T05','F03','T06','T08','T02',],axis=1)\n",
    "\n",
    "#'F13','F10','F12','F09','F16','F11','F05','F04'\n",
    "\n",
    "X = df_3.drop(['T04','F01','F02','F04','F06','F04','F08','F09','F07','F10',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=20)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(X_train)\n",
    "# transform train and test sets\n",
    "X_train_scaled_MM = scaler.transform(X_train)\n",
    "X_test_scaled_MM = scaler.transform(X_test)\n",
    "X_train_scaled_MM = pd.DataFrame(X_train_scaled_MM, columns=X_train.columns)\n",
    "X_test_scaled_MM = pd.DataFrame(X_test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "#LinearRegression_scaling\n",
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(X_train_scaled_MM,y_train)\n",
    "# prediction on Training data\n",
    "training_data_prediction_X_train_lin_reg = lin_reg_model.predict(X_train_scaled_MM)\n",
    "# prediction on Test data\n",
    "test_data_prediction_X_test_lin_reg = lin_reg_model.predict(X_test_scaled_MM)\n",
    "\n",
    "# R squared Error\n",
    "error_score_r2 = metrics.r2_score(y_train, training_data_prediction_X_train_lin_reg)\n",
    "error_score_MAE = metrics.mean_absolute_error(y_train, training_data_prediction_X_train_lin_reg)\n",
    "print(\"R squared Error : \", error_score_r2)\n",
    "print(\"mean_absolute_error : \", error_score_MAE)\n",
    "# R squared Error\n",
    "error_score_r2 = metrics.r2_score(y_test, test_data_prediction_X_test_lin_reg)\n",
    "error_score_MAE = metrics.mean_absolute_error(y_test, test_data_prediction_X_test_lin_reg)\n",
    "print(\"R squared Error : \", error_score_r2)\n",
    "print(\"mean_absolute_error : \", error_score_MAE)\n",
    "scores = cross_val_score(lin_reg_model, X_train, y_train, cv=2)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "# can tune other metrics, such as MSE\n",
    "scores = cross_val_score(lin_reg_model, X, y, cv=4)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "intercept = lin_reg_model.intercept_\n",
    "print(intercept)\n",
    "coeff = lin_reg_model.coef_\n",
    "features = X.columns\n",
    "df_coeff = pd.DataFrame({\"features\":features,\"coeff\":coeff})\n",
    "df_coeff.sort_values(\"coeff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2670add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nettemchandra sekhar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1769: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=16\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>T04</td>       <th>  R-squared:         </th> <td>   0.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Sep 2024</td> <th>  Prob (F-statistic):</th> <td>6.35e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:00:27</td>     <th>  Log-Likelihood:    </th> <td> -67.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    16</td>      <th>  AIC:               </th> <td>   141.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    13</td>      <th>  BIC:               </th> <td>   143.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  149.0959</td> <td>    8.352</td> <td>   17.851</td> <td> 0.000</td> <td>  131.052</td> <td>  167.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F03</th>   <td>  -89.9720</td> <td>   30.564</td> <td>   -2.944</td> <td> 0.011</td> <td> -156.002</td> <td>  -23.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F05</th>   <td>  -16.2437</td> <td>   36.558</td> <td>   -0.444</td> <td> 0.664</td> <td>  -95.222</td> <td>   62.735</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.308</td> <th>  Durbin-Watson:     </th> <td>   2.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.116</td> <th>  Jarque-Bera (JB):  </th> <td>   2.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.904</td> <th>  Prob(JB):          </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.400</td> <th>  Cond. No.          </th> <td>    12.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    T04   R-squared:                       0.841\n",
       "Model:                            OLS   Adj. R-squared:                  0.817\n",
       "Method:                 Least Squares   F-statistic:                     34.47\n",
       "Date:                Thu, 05 Sep 2024   Prob (F-statistic):           6.35e-06\n",
       "Time:                        10:00:27   Log-Likelihood:                -67.707\n",
       "No. Observations:                  16   AIC:                             141.4\n",
       "Df Residuals:                      13   BIC:                             143.7\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        149.0959      8.352     17.851      0.000     131.052     167.139\n",
       "F03          -89.9720     30.564     -2.944      0.011    -156.002     -23.942\n",
       "F05          -16.2437     36.558     -0.444      0.664     -95.222      62.735\n",
       "==============================================================================\n",
       "Omnibus:                        4.308   Durbin-Watson:                   2.745\n",
       "Prob(Omnibus):                  0.116   Jarque-Bera (JB):                2.285\n",
       "Skew:                          -0.904   Prob(JB):                        0.319\n",
       "Kurtosis:                       3.400   Cond. No.                         12.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_3.drop(['T04','F01','F02','F04','F06','F04','F08','F09','F07','F10',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=20)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(X_train)\n",
    "# transform train and test sets\n",
    "X_train_scaled_MM = scaler.transform(X_train)\n",
    "X_test_scaled_MM = scaler.transform(X_test)\n",
    "X_train_scaled_MM = pd.DataFrame(X_train_scaled_MM, columns=X_train.columns)\n",
    "X_test_scaled_MM = pd.DataFrame(X_test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "# Ensure y_train indices match X_train_scaled_MM\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_train_scaled_MM = X_train_scaled_MM.reset_index(drop=True)\n",
    "print(X_train_scaled_MM.index.equals(y_train.index))  # Should print True\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_sm = sm.add_constant(X_train_scaled_MM)\n",
    "model = sm.OLS(y_train,X_sm).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a21ad7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>T04</td>       <th>  R-squared:         </th> <td>   0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   44.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Sep 2024</td> <th>  Prob (F-statistic):</th> <td>1.04e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:00:28</td>     <th>  Log-Likelihood:    </th> <td> -87.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    21</td>      <th>  AIC:               </th> <td>   181.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    18</td>      <th>  BIC:               </th> <td>   184.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  708.7717</td> <td>  167.921</td> <td>    4.221</td> <td> 0.001</td> <td>  355.983</td> <td> 1061.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F03</th>   <td> -301.0656</td> <td>   89.880</td> <td>   -3.350</td> <td> 0.004</td> <td> -489.896</td> <td> -112.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F05</th>   <td>   -1.9354</td> <td>    5.094</td> <td>   -0.380</td> <td> 0.708</td> <td>  -12.637</td> <td>    8.767</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.566</td> <th>  Durbin-Watson:     </th> <td>   1.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.102</td> <th>  Jarque-Bera (JB):  </th> <td>   2.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.844</td> <th>  Prob(JB):          </th> <td>   0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.510</td> <th>  Cond. No.          </th> <td>    203.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    T04   R-squared:                       0.832\n",
       "Model:                            OLS   Adj. R-squared:                  0.814\n",
       "Method:                 Least Squares   F-statistic:                     44.73\n",
       "Date:                Thu, 05 Sep 2024   Prob (F-statistic):           1.04e-07\n",
       "Time:                        10:00:28   Log-Likelihood:                -87.832\n",
       "No. Observations:                  21   AIC:                             181.7\n",
       "Df Residuals:                      18   BIC:                             184.8\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        708.7717    167.921      4.221      0.001     355.983    1061.560\n",
       "F03         -301.0656     89.880     -3.350      0.004    -489.896    -112.235\n",
       "F05           -1.9354      5.094     -0.380      0.708     -12.637       8.767\n",
       "==============================================================================\n",
       "Omnibus:                        4.566   Durbin-Watson:                   1.884\n",
       "Prob(Omnibus):                  0.102   Jarque-Bera (JB):                2.720\n",
       "Skew:                          -0.844   Prob(JB):                        0.257\n",
       "Kurtosis:                       3.510   Cond. No.                         203.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_3.drop(['T04','F01','F02','F04','F06','F04','F08','F09','F07','F10',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_sm = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_sm).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c92e7bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>T04</td>       <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   18.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Sep 2024</td> <th>  Prob (F-statistic):</th> <td>3.33e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:00:22</td>     <th>  Log-Likelihood:    </th> <td> -75.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    21</td>      <th>  AIC:               </th> <td>   172.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    10</td>      <th>  BIC:               </th> <td>   183.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -436.6290</td> <td>  988.439</td> <td>   -0.442</td> <td> 0.668</td> <td>-2639.009</td> <td> 1765.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F01</th>   <td>   -1.6242</td> <td>    1.031</td> <td>   -1.576</td> <td> 0.146</td> <td>   -3.921</td> <td>    0.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F02</th>   <td>  -20.1282</td> <td>   25.492</td> <td>   -0.790</td> <td> 0.448</td> <td>  -76.927</td> <td>   36.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F03</th>   <td>   10.6529</td> <td>  373.419</td> <td>    0.029</td> <td> 0.978</td> <td> -821.377</td> <td>  842.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F04</th>   <td>    1.4020</td> <td>    2.569</td> <td>    0.546</td> <td> 0.597</td> <td>   -4.322</td> <td>    7.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F05</th>   <td>    3.8501</td> <td>    5.429</td> <td>    0.709</td> <td> 0.494</td> <td>   -8.246</td> <td>   15.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F06</th>   <td>   80.4688</td> <td>  342.222</td> <td>    0.235</td> <td> 0.819</td> <td> -682.049</td> <td>  842.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F07</th>   <td>   29.7462</td> <td>   20.789</td> <td>    1.431</td> <td> 0.183</td> <td>  -16.574</td> <td>   76.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F08</th>   <td>  139.4953</td> <td>   99.035</td> <td>    1.409</td> <td> 0.189</td> <td>  -81.169</td> <td>  360.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F09</th>   <td>  187.4257</td> <td>   99.234</td> <td>    1.889</td> <td> 0.088</td> <td>  -33.681</td> <td>  408.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F10</th>   <td>    0.0122</td> <td>    0.036</td> <td>    0.343</td> <td> 0.738</td> <td>   -0.067</td> <td>    0.092</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.733</td> <th>  Durbin-Watson:     </th> <td>   2.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.693</td> <th>  Jarque-Bera (JB):  </th> <td>   0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.352</td> <th>  Prob(JB):          </th> <td>   0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.390</td> <th>  Cond. No.          </th> <td>7.47e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    T04   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.900\n",
       "Method:                 Least Squares   F-statistic:                     18.99\n",
       "Date:                Thu, 05 Sep 2024   Prob (F-statistic):           3.33e-05\n",
       "Time:                        10:00:22   Log-Likelihood:                -75.140\n",
       "No. Observations:                  21   AIC:                             172.3\n",
       "Df Residuals:                      10   BIC:                             183.8\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -436.6290    988.439     -0.442      0.668   -2639.009    1765.751\n",
       "F01           -1.6242      1.031     -1.576      0.146      -3.921       0.672\n",
       "F02          -20.1282     25.492     -0.790      0.448     -76.927      36.671\n",
       "F03           10.6529    373.419      0.029      0.978    -821.377     842.683\n",
       "F04            1.4020      2.569      0.546      0.597      -4.322       7.126\n",
       "F05            3.8501      5.429      0.709      0.494      -8.246      15.946\n",
       "F06           80.4688    342.222      0.235      0.819    -682.049     842.986\n",
       "F07           29.7462     20.789      1.431      0.183     -16.574      76.066\n",
       "F08          139.4953     99.035      1.409      0.189     -81.169     360.159\n",
       "F09          187.4257     99.234      1.889      0.088     -33.681     408.533\n",
       "F10            0.0122      0.036      0.343      0.738      -0.067       0.092\n",
       "==============================================================================\n",
       "Omnibus:                        0.733   Durbin-Watson:                   2.062\n",
       "Prob(Omnibus):                  0.693   Jarque-Bera (JB):                0.760\n",
       "Skew:                          -0.352   Prob(JB):                        0.684\n",
       "Kurtosis:                       2.390   Cond. No.                     7.47e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.47e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_3.drop(['T04',],axis=1)\n",
    "#X = df_5.drop(['T07','F14','F17','F18',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_sm = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_sm).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0162d64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO Q^2 score:  0.7801879964908016\n",
      "LOO Mean Absolute Error:  13.776933296186739\n",
      "LOO Mean Squared Error:  329.91075506213906\n",
      "LOO Root Mean Squared Error:  18.16344557241657\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the Leave-One-Out cross-validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Drop the specified columns and set target variable\n",
    "X = df_3.drop(['T04','F01','F02','F04','F06','F04','F08','F09','F07','F10',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Apply MinMax Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Scale the features and store them in X_scaled\n",
    "\n",
    "\n",
    "# Initialize lists to store predictions and actual values\n",
    "y_pred_loo = []\n",
    "y_true_loo = []\n",
    "\n",
    "# Loop over each training/test split\n",
    "for train_index, test_index in loo.split(X_scaled):\n",
    "    X_train_loo, X_test_loo = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_loo, y_test_loo = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the Lasso model\n",
    "    linear_reg_model = LinearRegression()\n",
    "    linear_reg_model.fit(X_train_loo, y_train_loo)\n",
    "    \n",
    "    # Predict the left-out sample\n",
    "    y_pred_loo.append(linear_reg_model.predict(X_test_loo)[0])\n",
    "    y_true_loo.append(y_test_loo.values[0])\n",
    "\n",
    "# Convert lists to arrays\n",
    "y_pred_loo = np.array(y_pred_loo)\n",
    "y_true_loo = np.array(y_true_loo)\n",
    "\n",
    "# Calculate LOO performance metrics\n",
    "Q2_loo = r2_score(y_true_loo, y_pred_loo)\n",
    "MAE_loo = mean_absolute_error(y_true_loo, y_pred_loo)\n",
    "MSE_loo = mean_squared_error(y_true_loo, y_pred_loo)\n",
    "RMSE_loo = np.sqrt(MSE_loo)\n",
    "\n",
    "# Print the results\n",
    "print(\"LOO Q^2 score: \", Q2_loo)\n",
    "print(\"LOO Mean Absolute Error: \", MAE_loo)\n",
    "print(\"LOO Mean Squared Error: \", MSE_loo)\n",
    "print(\"LOO Root Mean Squared Error: \", RMSE_loo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204cfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fbd10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72354877 0.77708905]\n",
      "0.7503189112006536\n",
      "[0.80544268 0.78343327 0.78421519]\n",
      "0.7910303794493473\n",
      "[0.63233837 0.80737957 0.87436083 0.6996905 ]\n",
      "0.7534423196702167\n",
      "[0.41296406 0.85611597 0.70280101 0.89750681 0.56234409]\n",
      "0.68634638868959\n"
     ]
    }
   ],
   "source": [
    "# can tune other metrics, such as MSE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(X)\n",
    "# transform train and test sets\n",
    "X_scaled_MM = scaler.transform(X)\n",
    "X_scaled_MM = pd.DataFrame(X_scaled_MM, columns=X.columns)\n",
    "\n",
    "scores = cross_val_score(lin_reg_model, X_scaled_MM, y, cv=2)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "scores = cross_val_score(lin_reg_model, X_scaled_MM, y, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "scores = cross_val_score(lin_reg_model, X_scaled_MM, y, cv=4)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "scores = cross_val_score(lin_reg_model, X_scaled_MM, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9cd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc7887d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual Barrier (kJ/mol)  Predicted Barrier (kJ/mol)\n",
      "0                134.989547                  137.555501\n",
      "1                172.156151                  149.095873\n",
      "2                 60.127639                  102.158668\n",
      "3                 48.921745                   48.467121\n",
      "4                153.204294                  145.465530\n",
      "5                111.384753                  105.216797\n",
      "6                126.165031                  136.037384\n",
      "7                 84.663254                   61.763907\n",
      "8                158.160792                  147.477345\n",
      "9                 25.243201                   48.176127\n",
      "10                63.400511                   56.826722\n",
      "11                54.848496                   48.403879\n",
      "12                96.725090                  117.013169\n",
      "13                77.707753                   68.942979\n",
      "14                70.614886                   58.457988\n",
      "15                97.057793                  104.311948\n",
      "    Actual Barrier (kJ/mol)  Predicted Barrier (kJ/mol)\n",
      "21                56.669963                   54.651254\n",
      "24               134.842989                  135.098250\n",
      "23               111.601462                  108.779211\n",
      "5                 94.337618                  116.405375\n",
      "2                 80.539565                   60.562003\n"
     ]
    }
   ],
   "source": [
    "comparison_df_train_lin = pd.DataFrame({'Actual Barrier (kJ/mol)': y_train, 'Predicted Barrier (kJ/mol)': training_data_prediction_X_train_lin_reg})\n",
    "\n",
    "comparison_df_train_lin.to_excel('predicted_vs_actual_comparison_train_lin.xlsx', index=False)\n",
    "\n",
    "comparison_df_test_lin = pd.DataFrame({'Actual Barrier (kJ/mol)': y_test, 'Predicted Barrier (kJ/mol)': test_data_prediction_X_test_lin_reg})\n",
    "\n",
    "comparison_df_test_lin.to_excel('predicted_vs_actual_comparison_test_lin.xlsx', index=False)\n",
    "\n",
    "print(comparison_df_train_lin)\n",
    "\n",
    "print(comparison_df_test_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed0bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d99296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc64d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c92c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
