{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9be1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stat\n",
    "import pylab \n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.linear_model import LogisticRegression as LGR,Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fcfc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fe_CAAC_dataset = df = pd.read_excel(\"F:\\\\Nitrogen_activation\\\\rajaraman\\\\office\\\\ofifice\\\\jupyter\\\\Extension\\\\T07\\\\heatmap\\\\agostic\\\\LR_F08\\\\N2_activation_extension_T07_heatmap_agostaic_descrptors.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4e6a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df.drop(['F00','T01','T02','T03',],axis=1)\n",
    "df_2=df_1.drop([0,18,9])\n",
    "df_3=df_1.drop([0,18,9,8,26,17])\n",
    "df_4=df_1.drop([8,26,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958c61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de56ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared Error :  0.08322231883063402\n",
      "mean_absolute_error :  32.14089346936653\n",
      "R squared Error :  0.4529491577196345\n",
      "mean_absolute_error :  16.0154551108167\n",
      "[-0.42008472 -0.67822013]\n",
      "-0.549152424959099\n",
      "[-0.06953296  0.08642592  0.03521634 -0.15392286]\n",
      "-0.02545339202586988\n",
      "114.48813327218934\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F08</td>\n",
       "      <td>-30.358231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features      coeff\n",
       "0      F08 -30.358231"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = df.drop(['F01','F04','F05','F06','F07','F08','F09','F10','F11','F12','F13','F14','F15','T01','T02','T03','T04','T05'],axis=1)\n",
    "#X = df_3.drop(['F01','F02','F19','F08','F03','F14','F07','F15','F17','F18','F09','F16','F11','F05','F04','T01','T07','T03','T04','T05','F03','T06','T08','T02',],axis=1)\n",
    "\n",
    "#'F13','F10','F12','F09','F16','F11','F05','F04'\n",
    "\n",
    "X = df_3.drop(['T04','F01','F02','F03','F04','F06','F04','F05','F09','F07','F10',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=20)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(X_train)\n",
    "# transform train and test sets\n",
    "X_train_scaled_MM = scaler.transform(X_train)\n",
    "X_test_scaled_MM = scaler.transform(X_test)\n",
    "X_train_scaled_MM = pd.DataFrame(X_train_scaled_MM, columns=X_train.columns)\n",
    "X_test_scaled_MM = pd.DataFrame(X_test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "#LinearRegression_scaling\n",
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(X_train_scaled_MM,y_train)\n",
    "# prediction on Training data\n",
    "training_data_prediction_X_train_lin_reg = lin_reg_model.predict(X_train_scaled_MM)\n",
    "# prediction on Test data\n",
    "test_data_prediction_X_test_lin_reg = lin_reg_model.predict(X_test_scaled_MM)\n",
    "\n",
    "# R squared Error\n",
    "error_score_r2 = metrics.r2_score(y_train, training_data_prediction_X_train_lin_reg)\n",
    "error_score_MAE = metrics.mean_absolute_error(y_train, training_data_prediction_X_train_lin_reg)\n",
    "print(\"R squared Error : \", error_score_r2)\n",
    "print(\"mean_absolute_error : \", error_score_MAE)\n",
    "# R squared Error\n",
    "error_score_r2 = metrics.r2_score(y_test, test_data_prediction_X_test_lin_reg)\n",
    "error_score_MAE = metrics.mean_absolute_error(y_test, test_data_prediction_X_test_lin_reg)\n",
    "print(\"R squared Error : \", error_score_r2)\n",
    "print(\"mean_absolute_error : \", error_score_MAE)\n",
    "scores = cross_val_score(lin_reg_model, X_train, y_train, cv=2)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "# can tune other metrics, such as MSE\n",
    "scores = cross_val_score(lin_reg_model, X, y, cv=4)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "intercept = lin_reg_model.intercept_\n",
    "print(intercept)\n",
    "coeff = lin_reg_model.coef_\n",
    "features = X.columns\n",
    "df_coeff = pd.DataFrame({\"features\":features,\"coeff\":coeff})\n",
    "df_coeff.sort_values(\"coeff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2670add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nettemchandra sekhar\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1769: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=16\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>T04</td>       <th>  R-squared:         </th> <td>   0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Sep 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.279</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:21:01</td>     <th>  Log-Likelihood:    </th> <td> -81.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    16</td>      <th>  AIC:               </th> <td>   167.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    14</td>      <th>  BIC:               </th> <td>   169.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  114.4881</td> <td>   19.611</td> <td>    5.838</td> <td> 0.000</td> <td>   72.426</td> <td>  156.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F08</th>   <td>  -30.3582</td> <td>   26.929</td> <td>   -1.127</td> <td> 0.279</td> <td>  -88.116</td> <td>   27.399</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.542</td> <th>  Durbin-Watson:     </th> <td>   2.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.462</td> <th>  Jarque-Bera (JB):  </th> <td>   1.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.613</td> <th>  Prob(JB):          </th> <td>   0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.429</td> <th>  Cond. No.          </th> <td>    3.57</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    T04   R-squared:                       0.083\n",
       "Model:                            OLS   Adj. R-squared:                  0.018\n",
       "Method:                 Least Squares   F-statistic:                     1.271\n",
       "Date:                Thu, 05 Sep 2024   Prob (F-statistic):              0.279\n",
       "Time:                        09:21:01   Log-Likelihood:                -81.741\n",
       "No. Observations:                  16   AIC:                             167.5\n",
       "Df Residuals:                      14   BIC:                             169.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        114.4881     19.611      5.838      0.000      72.426     156.550\n",
       "F08          -30.3582     26.929     -1.127      0.279     -88.116      27.399\n",
       "==============================================================================\n",
       "Omnibus:                        1.542   Durbin-Watson:                   2.247\n",
       "Prob(Omnibus):                  0.462   Jarque-Bera (JB):                1.220\n",
       "Skew:                           0.613   Prob(JB):                        0.543\n",
       "Kurtosis:                       2.429   Cond. No.                         3.57\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_3.drop(['T04','F01','F02','F03','F04','F06','F04','F05','F09','F07','F10',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=20)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(X_train)\n",
    "# transform train and test sets\n",
    "X_train_scaled_MM = scaler.transform(X_train)\n",
    "X_test_scaled_MM = scaler.transform(X_test)\n",
    "X_train_scaled_MM = pd.DataFrame(X_train_scaled_MM, columns=X_train.columns)\n",
    "X_test_scaled_MM = pd.DataFrame(X_test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "# Ensure y_train indices match X_train_scaled_MM\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_train_scaled_MM = X_train_scaled_MM.reset_index(drop=True)\n",
    "print(X_train_scaled_MM.index.equals(y_train.index))  # Should print True\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_sm = sm.add_constant(X_train_scaled_MM)\n",
    "model = sm.OLS(y_train,X_sm).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a21ad7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>T04</td>       <th>  R-squared:         </th> <td>   0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Sep 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.112</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:21:03</td>     <th>  Log-Likelihood:    </th> <td> -105.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    21</td>      <th>  AIC:               </th> <td>   214.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    19</td>      <th>  BIC:               </th> <td>   216.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   36.4443</td> <td>   36.665</td> <td>    0.994</td> <td> 0.333</td> <td>  -40.297</td> <td>  113.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F08</th>   <td> -168.2857</td> <td>  101.126</td> <td>   -1.664</td> <td> 0.112</td> <td> -379.944</td> <td>   43.373</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.980</td> <th>  Durbin-Watson:     </th> <td>   1.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.225</td> <th>  Jarque-Bera (JB):  </th> <td>   1.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.754</td> <th>  Prob(JB):          </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.964</td> <th>  Cond. No.          </th> <td>    13.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    T04   R-squared:                       0.127\n",
       "Model:                            OLS   Adj. R-squared:                  0.081\n",
       "Method:                 Least Squares   F-statistic:                     2.769\n",
       "Date:                Thu, 05 Sep 2024   Prob (F-statistic):              0.112\n",
       "Time:                        09:21:03   Log-Likelihood:                -105.16\n",
       "No. Observations:                  21   AIC:                             214.3\n",
       "Df Residuals:                      19   BIC:                             216.4\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.4443     36.665      0.994      0.333     -40.297     113.185\n",
       "F08         -168.2857    101.126     -1.664      0.112    -379.944      43.373\n",
       "==============================================================================\n",
       "Omnibus:                        2.980   Durbin-Watson:                   1.514\n",
       "Prob(Omnibus):                  0.225   Jarque-Bera (JB):                1.991\n",
       "Skew:                           0.754   Prob(JB):                        0.369\n",
       "Kurtosis:                       2.964   Cond. No.                         13.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_3.drop(['T04','F01','F02','F03','F04','F06','F04','F05','F09','F07','F10',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_sm = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_sm).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c92e7bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>T04</td>       <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   18.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Sep 2024</td> <th>  Prob (F-statistic):</th> <td>3.33e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:21:03</td>     <th>  Log-Likelihood:    </th> <td> -75.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    21</td>      <th>  AIC:               </th> <td>   172.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    10</td>      <th>  BIC:               </th> <td>   183.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -436.6290</td> <td>  988.439</td> <td>   -0.442</td> <td> 0.668</td> <td>-2639.009</td> <td> 1765.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F01</th>   <td>   -1.6242</td> <td>    1.031</td> <td>   -1.576</td> <td> 0.146</td> <td>   -3.921</td> <td>    0.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F02</th>   <td>  -20.1282</td> <td>   25.492</td> <td>   -0.790</td> <td> 0.448</td> <td>  -76.927</td> <td>   36.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F03</th>   <td>   10.6529</td> <td>  373.419</td> <td>    0.029</td> <td> 0.978</td> <td> -821.377</td> <td>  842.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F04</th>   <td>    1.4020</td> <td>    2.569</td> <td>    0.546</td> <td> 0.597</td> <td>   -4.322</td> <td>    7.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F05</th>   <td>    3.8501</td> <td>    5.429</td> <td>    0.709</td> <td> 0.494</td> <td>   -8.246</td> <td>   15.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F06</th>   <td>   80.4688</td> <td>  342.222</td> <td>    0.235</td> <td> 0.819</td> <td> -682.049</td> <td>  842.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F07</th>   <td>   29.7462</td> <td>   20.789</td> <td>    1.431</td> <td> 0.183</td> <td>  -16.574</td> <td>   76.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F08</th>   <td>  139.4953</td> <td>   99.035</td> <td>    1.409</td> <td> 0.189</td> <td>  -81.169</td> <td>  360.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F09</th>   <td>  187.4257</td> <td>   99.234</td> <td>    1.889</td> <td> 0.088</td> <td>  -33.681</td> <td>  408.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F10</th>   <td>    0.0122</td> <td>    0.036</td> <td>    0.343</td> <td> 0.738</td> <td>   -0.067</td> <td>    0.092</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.733</td> <th>  Durbin-Watson:     </th> <td>   2.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.693</td> <th>  Jarque-Bera (JB):  </th> <td>   0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.352</td> <th>  Prob(JB):          </th> <td>   0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.390</td> <th>  Cond. No.          </th> <td>7.47e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    T04   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.900\n",
       "Method:                 Least Squares   F-statistic:                     18.99\n",
       "Date:                Thu, 05 Sep 2024   Prob (F-statistic):           3.33e-05\n",
       "Time:                        09:21:03   Log-Likelihood:                -75.140\n",
       "No. Observations:                  21   AIC:                             172.3\n",
       "Df Residuals:                      10   BIC:                             183.8\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -436.6290    988.439     -0.442      0.668   -2639.009    1765.751\n",
       "F01           -1.6242      1.031     -1.576      0.146      -3.921       0.672\n",
       "F02          -20.1282     25.492     -0.790      0.448     -76.927      36.671\n",
       "F03           10.6529    373.419      0.029      0.978    -821.377     842.683\n",
       "F04            1.4020      2.569      0.546      0.597      -4.322       7.126\n",
       "F05            3.8501      5.429      0.709      0.494      -8.246      15.946\n",
       "F06           80.4688    342.222      0.235      0.819    -682.049     842.986\n",
       "F07           29.7462     20.789      1.431      0.183     -16.574      76.066\n",
       "F08          139.4953     99.035      1.409      0.189     -81.169     360.159\n",
       "F09          187.4257     99.234      1.889      0.088     -33.681     408.533\n",
       "F10            0.0122      0.036      0.343      0.738      -0.067       0.092\n",
       "==============================================================================\n",
       "Omnibus:                        0.733   Durbin-Watson:                   2.062\n",
       "Prob(Omnibus):                  0.693   Jarque-Bera (JB):                0.760\n",
       "Skew:                          -0.352   Prob(JB):                        0.684\n",
       "Kurtosis:                       2.390   Cond. No.                     7.47e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.47e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_3.drop(['T04',],axis=1)\n",
    "#X = df_5.drop(['T07','F14','F17','F18',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_sm = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_sm).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0162d64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO Q^2 score:  -0.030512146989434497\n",
      "LOO Mean Absolute Error:  30.47984185925724\n",
      "LOO Mean Squared Error:  1546.6718608920896\n",
      "LOO Root Mean Squared Error:  39.32774924772698\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the Leave-One-Out cross-validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Drop the specified columns and set target variable\n",
    "X = df_3.drop(['T04','F01','F02','F03','F04','F06','F04','F05','F09','F07','F10',],axis=1)\n",
    "y = df_3['T04']# loading the linear regression model\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Apply MinMax Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Scale the features and store them in X_scaled\n",
    "\n",
    "\n",
    "# Initialize lists to store predictions and actual values\n",
    "y_pred_loo = []\n",
    "y_true_loo = []\n",
    "\n",
    "# Loop over each training/test split\n",
    "for train_index, test_index in loo.split(X_scaled):\n",
    "    X_train_loo, X_test_loo = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_loo, y_test_loo = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the Lasso model\n",
    "    linear_reg_model = LinearRegression()\n",
    "    linear_reg_model.fit(X_train_loo, y_train_loo)\n",
    "    \n",
    "    # Predict the left-out sample\n",
    "    y_pred_loo.append(linear_reg_model.predict(X_test_loo)[0])\n",
    "    y_true_loo.append(y_test_loo.values[0])\n",
    "\n",
    "# Convert lists to arrays\n",
    "y_pred_loo = np.array(y_pred_loo)\n",
    "y_true_loo = np.array(y_true_loo)\n",
    "\n",
    "# Calculate LOO performance metrics\n",
    "Q2_loo = r2_score(y_true_loo, y_pred_loo)\n",
    "MAE_loo = mean_absolute_error(y_true_loo, y_pred_loo)\n",
    "MSE_loo = mean_squared_error(y_true_loo, y_pred_loo)\n",
    "RMSE_loo = np.sqrt(MSE_loo)\n",
    "\n",
    "# Print the results\n",
    "print(\"LOO Q^2 score: \", Q2_loo)\n",
    "print(\"LOO Mean Absolute Error: \", MAE_loo)\n",
    "print(\"LOO Mean Squared Error: \", MSE_loo)\n",
    "print(\"LOO Root Mean Squared Error: \", RMSE_loo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204cfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fbd10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03921471 -0.06503472]\n",
      "-0.012910002110460617\n",
      "[ 0.14071657 -0.01375953  0.06504676]\n",
      "0.06400126889107412\n",
      "[-0.06953296  0.08642592  0.03521634 -0.15392286]\n",
      "-0.025453392025869742\n",
      "[-0.80289966 -0.03410897  0.35334202  0.10747428 -0.74755471]\n",
      "-0.22474940658337972\n"
     ]
    }
   ],
   "source": [
    "# can tune other metrics, such as MSE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(X)\n",
    "# transform train and test sets\n",
    "X_scaled_MM = scaler.transform(X)\n",
    "X_scaled_MM = pd.DataFrame(X_scaled_MM, columns=X.columns)\n",
    "\n",
    "scores = cross_val_score(lin_reg_model, X_scaled_MM, y, cv=2)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "scores = cross_val_score(lin_reg_model, X_scaled_MM, y, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "scores = cross_val_score(lin_reg_model, X_scaled_MM, y, cv=4)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "scores = cross_val_score(lin_reg_model, X_scaled_MM, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9cd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc7887d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual Barrier (kJ/mol)  Predicted Barrier (kJ/mol)\n",
      "0                134.989547                  106.564680\n",
      "1                172.156151                   91.648179\n",
      "2                 60.127639                  113.857859\n",
      "3                 48.921745                   84.159915\n",
      "4                153.204294                   92.053356\n",
      "5                111.384753                  114.488133\n",
      "6                126.165031                  106.009438\n",
      "7                 84.663254                   85.225380\n",
      "8                158.160792                   91.273016\n",
      "9                 25.243201                   84.129902\n",
      "10                63.400511                   84.925249\n",
      "11                54.848496                   84.430033\n",
      "12                96.725090                  112.852420\n",
      "13                77.707753                   85.075314\n",
      "14                70.614886                   86.696021\n",
      "15                97.057793                  111.982041\n",
      "    Actual Barrier (kJ/mol)  Predicted Barrier (kJ/mol)\n",
      "21                56.669963                   85.075314\n",
      "24               134.842989                  107.390040\n",
      "23               111.601462                  111.749440\n",
      "5                 94.337618                  112.942460\n",
      "2                 80.539565                   86.005720\n"
     ]
    }
   ],
   "source": [
    "comparison_df_train_lin = pd.DataFrame({'Actual Barrier (kJ/mol)': y_train, 'Predicted Barrier (kJ/mol)': training_data_prediction_X_train_lin_reg})\n",
    "\n",
    "comparison_df_train_lin.to_excel('predicted_vs_actual_comparison_train_lin.xlsx', index=False)\n",
    "\n",
    "comparison_df_test_lin = pd.DataFrame({'Actual Barrier (kJ/mol)': y_test, 'Predicted Barrier (kJ/mol)': test_data_prediction_X_test_lin_reg})\n",
    "\n",
    "comparison_df_test_lin.to_excel('predicted_vs_actual_comparison_test_lin.xlsx', index=False)\n",
    "\n",
    "print(comparison_df_train_lin)\n",
    "\n",
    "print(comparison_df_test_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed0bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d99296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc64d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c92c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
